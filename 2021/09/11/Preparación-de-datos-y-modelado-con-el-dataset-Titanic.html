<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Preparación De Datos Y Modelado Con El Dataset Titanic | Portafolio José Vilaseca</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Preparación De Datos Y Modelado Con El Dataset Titanic" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Preparación de datos y modelado para el dataset Titanic" />
<meta property="og:description" content="Preparación de datos y modelado para el dataset Titanic" />
<link rel="canonical" href="https://josevilaseca.github.io/Portafolio-ML/2021/09/11/Preparaci%C3%B3n-de-datos-y-modelado-con-el-dataset-Titanic.html" />
<meta property="og:url" content="https://josevilaseca.github.io/Portafolio-ML/2021/09/11/Preparaci%C3%B3n-de-datos-y-modelado-con-el-dataset-Titanic.html" />
<meta property="og:site_name" content="Portafolio José Vilaseca" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-09-11T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2021-09-11T00:00:00-05:00","url":"https://josevilaseca.github.io/Portafolio-ML/2021/09/11/Preparaci%C3%B3n-de-datos-y-modelado-con-el-dataset-Titanic.html","@type":"BlogPosting","headline":"Preparación De Datos Y Modelado Con El Dataset Titanic","dateModified":"2021-09-11T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://josevilaseca.github.io/Portafolio-ML/2021/09/11/Preparaci%C3%B3n-de-datos-y-modelado-con-el-dataset-Titanic.html"},"description":"Preparación de datos y modelado para el dataset Titanic","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Portafolio-ML/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://josevilaseca.github.io/Portafolio-ML/feed.xml" title="Portafolio José Vilaseca" /><link rel="shortcut icon" type="image/x-icon" href="/Portafolio-ML/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Portafolio-ML/">Portafolio José Vilaseca</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Portafolio-ML/about/">About Me</a><a class="page-link" href="/Portafolio-ML/search/">Search</a><a class="page-link" href="/Portafolio-ML/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Preparación De Datos Y Modelado Con El Dataset Titanic</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-09-11T00:00:00-05:00" itemprop="datePublished">
        Sep 11, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Preparación de datos y modelado para el dataset Titanic</p>

<p>1) Importar librerías y paquetes</p>

<p>Además de hablar de las librerías y paquetes, me pareció interesante destacar ciertos conceptos que no fueron presentados en la clase y quizás alguna posible mejora para alguna parte del código en el caso de manejar datasets más pesados y más cómputo-dependientes.</p>

<p>Inicialmente, se importan las librerías necesarias como numpy y pandas para cálculos matemáticos y estructuras de datos además de matplotlib y seaborn para la parte de visualización de datos y gráficas.</p>

<p>Luego, se importan varias funcionalidades/modelos de la librería scikit learn. Los modelos importados y una breve explicación de ellos es la siguiente.</p>

<p><strong>SVC, Linear SVC</strong> son algoritmos del tipo Support vector machines, los cuales buscan definir una recta, plano o hiperplano (hablando de un SVM lineal) tal que la distancia entre esta recta y el punto más cercano de cada clase sea máxima.</p>

<p>Dentro de los <strong>algoritmos de árboles o ensembles</strong>, se utilizan un decisionTreeClassifier, un randomForestClassifier y XGBoost. El decisionTreeClassifier construye un único árbol y lo utiliza para hacer las predicciones. El random forest construye múltiples árboles armados utilizando bagging y luego al realizar una predicción se le da un peso al resultado de cada árbol del bosque y se decide qué predice el bosque (juntando las predicciones de cada uno y sus pesos). Por último, XGBoost utiliza una forma diferente de armar los árboles dado que son dependientes uno de otro, intentando mejorar las métricas con cada árbol nuevo.</p>

<p>También se utiliza la técnica de Gridsearch para tunear los hiperparámetros de los distintos algoritmos. Una mejor alternativa para un caso computacionalmente complejo sería utilizar randomsearch para ubicar los puntos de interés donde es muy probable encontrar óptimos en la cercanía y aplicar gridsearch en espacios pequeños cercanos a dichos puntos de interés.</p>

<p>2)  &gt; Cargar el dataset y mostrarlo</p>

<p>Para realizar estas dos tareas, se utilizan las funcionalidades de pandas llamadas read_csv para leer un archivo csv y cargarlo utilizando la estructura de datos llamada dataframe y head como forma de imprimir las primeras x filas (5 por defecto) del dataset de una forma prolija.</p>

<p>3)  &gt; Gestionar los valores faltantes</p>

<p>Se utiliza la función pd.isnull para identificar los valores faltantes de cada columna. Se dropean las columnas Cabin y ticket por la gran cantidad de valores faltantes.</p>

<p>Se observa una distribución relativamente parecida a una normal para el atributo age, pero con un leve sesgo hacia la derecha, lo que determinará la estrategia de imputación utilizada. Debido a este sesgo, elegir la mediana es una mejor alternativa que elegir la media. Si no tuviéramos este sesgo, la estrategia de imputación elegida sería la media.</p>

<p>Para el atributo fare, la distribución está fuertemente sesgada hacia la derecha, por lo que se elige la mediana como valor a imputar. Alternativamente, se podría elegir aplicar una transformación a los datos para que su distribución se asemeje más a una normal. 2 estrategias para esto podrían ser aplicar el logaritmo natural a los valores del atributo o alguna de las variantes de la transformación “Box and Cox” (1964) presentada en applied-predictivemodeling, presente en la bibliografía del curso.</p>

<p>4)  &gt; Graficar los datos</p>

<p>Se grafican varios atributos en relación al atributo a predecir para formar unas hipótesis iniciales sobre si algún atributo está correlacionado con la variable a predecir. Las librerías para</p>

<p>hacer esto son seaborn y matplotlib.pyplot. Aquí se pueden observar ratios como la proporción de mujeres que sobrevivieron o indicios como qué clase es la que presentó más proporción de personas que sobrevivieron.</p>

<p>5)  &gt; Feature Engineering</p>

<p>En la parte de feature engineering, lo primero que se hace es encodear los atributos categóricos a valores enteros. Se podría realizar mediante one hot encoding pero en este notebok, se decide no hacerlo.</p>

<p>Una hipótesis muy interesante provista por Samson Qian (creador del notebook en kaggle) es que el titulo de la persona puede influir en si esta sobrevivió o no. Desde mi punto de vista personal, quizás esto podría estar agregando un atributo fuertemente correlacionado con Sex. Luego de calcular la matriz de correlación, se ve que la correlación es muy baja, lo que no me parece intuitivo, dado que la gran mayoría de los ejemplos de títulos (más del 90%) son Mr, Mrs y Miss lols cuales se podrían relacionar directamente con el género.</p>

<p>(Imagen de correlación provista debajo)</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-09-11-Preparación-de-datos-y-modelado-con-el-dataset-Titanic/media/image1.jpg" alt="" /></p>

<p>Luego, se normalizan los datos con el standard scaler (estandarización Z).</p>

<h1 id="pasos-opcionales">Pasos Opcionales</h1>

<p>Como no se requiere, no voy a comentar todos los aspectos sobre la parte de modelado, predicción y evaluación de rendimiento, pero sí los incluí en el código y me interesaría remarcar algunos puntos.</p>

<p>Se puede ver que los mejores resultados a primera vista, pues la única métrica que estamos mirando es accuracy (no es suficiente para tomar una decisión sobre si el modelo es bueno o no), son los de SVC y random forest, alrededor de 0.82 – 0.83, pero varía cada vez, dado que el random forest tiene un grado de aleatoriedad en su construcción.</p>

<p>Cabe destacar que, aunque los resultados del random forest sean los mejores para este set de testeo, el modelo tardó 60 segundos en entrenar, mientras que SVC tardó 1.2 segundos y la regresión logística 3.4s. Para conjuntos de datos más grandes o muy cambiantes para los que se necesita reentrenar el modelo constantemente, habría que ver si los pocos puntos de mejora en la accuracy justifican el costo inmensamente mayor de entrenamiento del modelo de random forest. Probablemente los tiempos de inferencia también sean mucho mayores en el random forest.</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-09-11-Preparación-de-datos-y-modelado-con-el-dataset-Titanic/media/image2.jpg" alt="" /></p>

  </div><a class="u-url" href="/Portafolio-ML/2021/09/11/Preparaci%C3%B3n-de-datos-y-modelado-con-el-dataset-Titanic.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Portafolio-ML/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Portafolio-ML/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Portafolio-ML/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/https%3A%2F%2Fgithub.com%2FJoseVilaseca" title="https://github.com/JoseVilaseca"><svg class="svg-icon grey"><use xlink:href="/Portafolio-ML/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
