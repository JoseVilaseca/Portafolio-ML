<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Clustering | Portafolio José Vilaseca</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Clustering" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Clustering" />
<meta property="og:description" content="Clustering" />
<link rel="canonical" href="https://josevilaseca.github.io/Portafolio-ML/2021/10/09/Clustering.html" />
<meta property="og:url" content="https://josevilaseca.github.io/Portafolio-ML/2021/10/09/Clustering.html" />
<meta property="og:site_name" content="Portafolio José Vilaseca" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-10-09T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2021-10-09T00:00:00-05:00","url":"https://josevilaseca.github.io/Portafolio-ML/2021/10/09/Clustering.html","@type":"BlogPosting","headline":"Clustering","dateModified":"2021-10-09T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://josevilaseca.github.io/Portafolio-ML/2021/10/09/Clustering.html"},"description":"Clustering","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Portafolio-ML/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://josevilaseca.github.io/Portafolio-ML/feed.xml" title="Portafolio José Vilaseca" /><link rel="shortcut icon" type="image/x-icon" href="/Portafolio-ML/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Portafolio-ML/">Portafolio José Vilaseca</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Portafolio-ML/about/">About Me</a><a class="page-link" href="/Portafolio-ML/search/">Search</a><a class="page-link" href="/Portafolio-ML/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Clustering</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-10-09T00:00:00-05:00" itemprop="datePublished">
        Oct 9, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><strong>Clustering</strong></p>

<p>En este post me gustaría hablar sobre diferentes estrategias de clustering de datos para problemas supervisados y no supervisados.</p>

<p>Previo a un análisis de casos especiales, me parece pertinente hacer una breve introducción al concepto de clustering. Supongamos que se tiene un conjunto de datos estructurado o tabular como por ejemplo un archivo .csv. En él habrá una gran cantidad de filas o ejemplos y otra cantidad de columnas o atributos. ¿Cómo podríamos hacer para extraer información relevante de este conjunto de datos? Si nuestro dataset contiene información de clientes de un supermercado y de los artículos que este compra, algo que podríamos querer hacer es agrupar a diferentes tipos de clientes para poder realizar ofertas direccionadas. El proceso de agrupar o armar clusters es lo que se conoce como clustering y tiene el propósito de extraer información mediante diferentes formas de agrupación.</p>

<p><strong>Hierarchical clustering</strong></p>

<p>El clustering jerárquico es un método de análisis de clusters que busca construir una jerarquía de clusters. Este tipo de clustering se basa en la idea que explica que un objeto está más relacionado con un ejemplo cercano que con uno que está a una distancia mayor. Por lo tanto, el clustering jerárquico conecta objetos o ejemplos basándose en la distancia entre ambos. A distancias diferentes, se formarán distintos clusters, que se pueden representar utilizando un dendograma.</p>

<p>Existen 2 estrategias para clustering jerárquico:</p>

<p>Agglomerative: Cada ejemplo comienza en su cluster propio y a medida que se aumenta la distancia (a medida que nos movemos hacia arriba en la jerarquía), se irán formando las agrupaciones.</p>

<p>Divisive: Los ejemplos comienzan agrupadops en un único cluster y se van separando recursivamente a medida que bajamos en la jerarquía.</p>

<p>Existen diferentes modos de medir las distancias entre clusters. Cada una tiene sus casos de aplicación particular, pero en el siguiente ejercicio, analizaremos el propósito de 2 de estos modos (complete link y single link).</p>

<p><strong>K-Means</strong></p>

<p>K-means es un tipo de clustering en el que el número de clusters a generar es un parámetro del algoritmo (k). Este algoritmo iniciará escogiendo k puntos aleatorios del dataset (centroides) y asignando un cluster a cada punto dependiendo de qué centroide esté más cerca de él. Luego, de forma iterativa, se vuelven a calcular los centroides tal que estos centroides (no necesariamente pertenecientes al dataset) minimicen la suma de las distancias a todos los puntos del cluster. Luego, se reclusterizan los puntos dependiendo de la proximidad de los centroides recalculados. La heurística termina cuando los centroides se hayan estabilizado o luego de un número máximo de iteraciones. Este algoritmo no siempre devuelve los mismos agrupamientos debido a la inicialización randómica de los centroides, por lo que es una buena práctica correr el algoritmo múltiples veces.</p>

<p><strong>Ejercicio</strong></p>

<p>Se desea agrupar los ejemplos del dataset ripley provisto por rapidminer en clusters.</p>

<p>Nota: Es de crucial importancia normalizar los atributos previo a realizar clustering, pues las formas de clustering discutidas utilizan la distancia euclídea para medir la similaridad entre ejemplos o clusters.</p>

<p><img src="assets/img/2021-10-09-Clustering/media/image1.png" alt="Diagrama Descripción generada automáticamente" /></p>

<p><strong>Agglomerative clustering</strong></p>

<p>Para el agglomerative clustering, se decide hacer una comparación entre la utilización entre complete link y single link.</p>

<p>Complete link y distancia euclídea</p>

<p><img src="assets/img/2021-10-09-Clustering/media/image2.png" alt="Gráfico, Gráfico de dispersión Descripción generada automáticamente" /></p>

<p>Single link y distancia euclídea</p>

<p><img src="assets/img/2021-10-09-Clustering/media/image3.png" alt="Gráfico, Gráfico de dispersión Descripción generada automáticamente" /></p>

<p>Como se puede observar en las imágenes anteriores, la utilización de comlpete link obtiene clusters más parejos (uniformes) y distancias intraclusters medias menores que el single link. Aquí ya podemos entender el propósito de la utilización de cada uno.</p>

<p>Si se desea obtener clusters uniformes y parejos, la mejor forma de medir distancias entre clusters es complete link.</p>

<p>Si, por el contrario se desea localizar datos extremos o outliers, single link es la forma de distancia a elegir.</p>

<p><strong>Resultados</strong> para agglomerative clustering con complete link:</p>

<p>Avg. within cluster distance: -31.972</p>

<p>Avg. within cluster distance for cluster 0: -37.551</p>

<p>Avg. within cluster distance for cluster 1: -13.095</p>

<p>Avg. within cluster distance for cluster 2: -34.942</p>

<p><strong>Top-Down Clustering</strong></p>

<p>En cuanto a top-down clustering, se decide utilizar k-means con Max depth=5 y</p>

<p>Max leaf size=1.</p>

<p><img src="assets/img/2021-10-09-Clustering/media/image4.png" alt="Gráfico, Gráfico de dispersión Descripción generada automáticamente" /></p>

<p><strong>Resultados:</strong></p>

<p>kmeans k=2</p>

<p>Avg. within cluster distance: -36.971</p>

<p>Avg. within cluster distance for cluster 0: -55.705</p>

<p>Avg. within cluster distance for cluster 1: -23.788</p>

<p>Avg. within cluster distance for cluster 2: -13.534</p>

<p><strong>Conclusiones</strong></p>

<p>Se puede observar que la estrategia de aglomerative clustering obtuvo una menor distancia promedio intercluster que la estrategia utilizando top-down clustering con kmeans. Debido a esto, podemos argumentar que para este dataset, la mejor estrategia es la de agglomerative clustering</p>

<p><strong>Referencias:</strong></p>

<p>https://docs.rapidminer.com/latest/studio/operators/modeling/segmentation/agglomerative_clustering.html</p>

  </div><a class="u-url" href="/Portafolio-ML/2021/10/09/Clustering.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Portafolio-ML/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Portafolio-ML/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Portafolio-ML/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/Portafolio-ML/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/Portafolio-ML/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
