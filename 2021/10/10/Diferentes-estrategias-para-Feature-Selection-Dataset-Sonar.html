<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Diferentes Estrategias Para Feature Selection Dataset Sonar | Portafolio José Vilaseca</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Diferentes Estrategias Para Feature Selection Dataset Sonar" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Feature selection para el dataset Sonar" />
<meta property="og:description" content="Feature selection para el dataset Sonar" />
<link rel="canonical" href="https://josevilaseca.github.io/Portafolio-ML/2021/10/10/Diferentes-estrategias-para-Feature-Selection-Dataset-Sonar.html" />
<meta property="og:url" content="https://josevilaseca.github.io/Portafolio-ML/2021/10/10/Diferentes-estrategias-para-Feature-Selection-Dataset-Sonar.html" />
<meta property="og:site_name" content="Portafolio José Vilaseca" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-10-10T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2021-10-10T00:00:00-05:00","url":"https://josevilaseca.github.io/Portafolio-ML/2021/10/10/Diferentes-estrategias-para-Feature-Selection-Dataset-Sonar.html","@type":"BlogPosting","headline":"Diferentes Estrategias Para Feature Selection Dataset Sonar","dateModified":"2021-10-10T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://josevilaseca.github.io/Portafolio-ML/2021/10/10/Diferentes-estrategias-para-Feature-Selection-Dataset-Sonar.html"},"description":"Feature selection para el dataset Sonar","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Portafolio-ML/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://josevilaseca.github.io/Portafolio-ML/feed.xml" title="Portafolio José Vilaseca" /><link rel="shortcut icon" type="image/x-icon" href="/Portafolio-ML/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Portafolio-ML/">Portafolio José Vilaseca</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Portafolio-ML/about/">About Me</a><a class="page-link" href="/Portafolio-ML/search/">Search</a><a class="page-link" href="/Portafolio-ML/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Diferentes Estrategias Para Feature Selection   Dataset Sonar</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-10-10T00:00:00-05:00" itemprop="datePublished">
        Oct 10, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="feature-selection-para-el-dataset-sonar">Feature selection para el dataset Sonar</h1>

<p>Feature selection es una estrategia muy importante para generar modelos buenos y robustos. Si mantenemos atributos que contengan una gran cantidad de ruido, identificar los patrones que se buscan en un set de datos será una tarea difícil, hasta para los algoritmos de aprendizaje más <strong>modernos.</strong></p>

<p><strong>Por este motivo, existen diferentes técnicas para seleccionar los mejores atributos para nuestro modelo. Estas caen en 2 categorías, las del tipo filtro y las del tipo wrapper.</strong></p>

<p>Las técnicas del tipo filtro refieren a una elección de artibutos a remover sin incluir el proceso de aprendizaje/modelado. Dentro de esta categoría, podemos encontrar a la eliminación de atributos por conocimiento del dataset o a la eliminación de atributos conocidos que no aportan a los modelos (id o nombre en algunos casos). También, técnicas como el análisis de la correlación de los atributos con la salida y entre sí, caen dentro de esta categoría. Por último, otra técnica de tipo filtro sería utilizar PCA, tanto para utilizar los primeros componentes principales en el modelado como para identificar los atributos con coeficientes mayores en el cálculo de los primeros componentes principales.</p>

<p><strong>Por otra parte, las técnicas de tipo wrapper seleccionan predictores de forma iterativa incluyendo los pasos de entrenamiento y validación para decidir cuáles predictores son los que generan los mejores modelos. Como una estrategia de fuerza bruta, o sea probar todas las combinaciones posibles es increíblemente costoso de un punto de vista computacional (orden exponencial – 2 a la n para n atributos), surgen heurísticas variadas para atacar esta problemática. Algunos ejemplos de estas son: forward propagation, backward elimination y evolutionary feature selection. Estas heurísticas serán analizadas a continuación.</strong></p>

<h3 id="forward-selection">Forward Selection</h3>

<p><strong>Como primer paso, se generan modelos con cada uno de los predictores del dataset (se utiliza únicamente 1 predictor). El atributo con el que fue entrenado el modelo que obtuvo mejores resultados, será seleccionado y se pasa a la siguiente iteración. Luego, se entrenan modelos con 2 atributos, las combinaciones entre el atributo elegido en el paso anterior y el resto de los predictores (n-1 modelos con n predictores). Dentro de estos modelos, se compara la performance entre sí y con el modelo que utilizó únicamente 1 atributo. Si la performance no mejora respecto al modelo con 1 atributo menos, termina la heurística. Si, efectivamente, se logra obtener una mayor performance, se sigue iterando hasta llegar a la condición de corte mencionada en la oración anterior. Se puede ver que el número de entrenamientos necesarios para esta heurística posee una cota superior dada por la suma de los primeros n naturales de 1 hasta la cantidad de predictores. Esta cantidad de modelos entrenados es mucho menor que la cantidad si utilizamos el enfoque de fuerza bruta (para 100 atributos existen como máximo 5050 combinaciones para forward selection y 1,267,650,600,228,229,401,496,703,205,375 para el enfoque de fuerza bruta).</strong></p>

<h3 id="backward-elimination">Backward elimination</h3>

<p><strong>Esta heurística se puede pensar como la opuesta/inversa de forward selection. En vez de empezar con 0 e ir agregando atributos iterativamente, aquí se comienza con la totalidad de los predictores. Luego de entrenar el primer modelo con todos los atributos, se mide la performance de los modelos que poseen todos los predictores menos 1. Si existe alguno de estos nuevos modelos que posea una mejor performance que la que obtuvo el modelo de la iteración anterior (modelo entrenado con todos los predictores), se descarta el atributo no utilizado y se itera nuevamente. En el caso que la performance no mejore, termina la heurística.</strong></p>

<p><strong>Las 2 heurísticas mencionadas son claramente mucho más eficientes desde el punto de vista computacional que la fuerza bruta, pero tienen sus desventajas. Son muy susceptibles a seleccionar óptimos locales y no el óptimo global. Debido a esto, la performance obtenida con estos enfoques normalmente es inferior a la obtenida con el enfoque de fuerza bruta. Entonces, ¿cuál sería nuestra opción si quisiéramos lo mejor de los dos mundos?</strong></p>

<h3 id="algoritmos-evolutivos-para-la-selección-de-atributos">Algoritmos Evolutivos para la selección de atributos.</h3>

<p><strong>Los algoritmos evolutivos son una técnica de optimización que se basa en la selección natural. En resumen, esta estrategia funciona inicialmente generando una población inicial (combinaciones de predictores en nuestro caso). Luego, de forma iterativa hasta llegar a un máximo de iteraciones (se les llama generaciones) o a alguna otra condición de corte, se aplican los siguientes pasos. Cruzamiento: Se cruzan los individuos de la población. Mutación: se muta a los individuos (normalmente involucra un cambio pequeño randómico como seleccionar un atributo nuevo o des-seleccionar uno). Evaluación: se evalúa a la población. En nuestro caso esto se hará con la exactitud (por ejemplo) de los modelos generados con los atributos representados por cada individuo de la población. Selección: se seleccionan losindividuos que posean mejores métricas.</strong></p>

<p><strong>Esta estrategia, aunque tiene un costo computacional mayor que las 2 heurísticas antes mencionadas, suele llegar al óptimo global o de los contrario a una solución mejor que la obtenida con dichas heurísticas. El costo igualmente, no se compara con el de la fuerza bruta.</strong></p>

<h3 id="dataset-sonar"><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image1.png" alt="" />Dataset Sonar</h3>

<p><strong>Este dataset contiene medidas realizadas al fondo marino utilizando un sonar. Cada medida (ejemplo) contiene múltiples bandas de frecuencia (predictores) y una clase definida: rock o mine. La idea es poder detectar la presencia de minas en el fondo marino. Al graficar los datos, se puede observar el espectro de frecuencia para cada objeto. Dichos espectros, difieren claramente en algunas zonas específicas. Se definen los siguientes intervalos de atributos como zonas de interés. La idea es utilizar diferentes técnicas de feature selection para observar los atributos que se eligen y la performance que se obtiene.</strong></p>

<p><strong>Intervalos</strong></p>

<p>1)  9-13</p>

<p>2)  19-25</p>

<p>3)  33-37</p>

<p>4)  42-50</p>

<h3 id="ejercicio-1-benchmarking">Ejercicio 1: Benchmarking</h3>

<p>Se entrena un modelo con todos los predictores y el algoritmo naive bayes.</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image2.png" alt="" />Se obtienen los mismos resultados con o sin la corrección de Laplace.</p>

<p>##</p>

<p>##</p>

<h3 id="ejercicio-2-forward-selection">Ejercicio 2: Forward selection</h3>

<p>Se entrena un modelo con los predictores seleccionados con la heurística forward selection y el algoritmo naive bayes.</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image3.png" alt="" /><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image3.png" alt="" /></p>

<p>Atributos seleccionados: 12, 15, 17, 18</p>

<p>El algoritmo encuentra un máximo local (atributo 12) en 4 iteraciones.</p>

<h3 id="ejercicio-3-backward-elimination">Ejercicio 3: Backward Elimination</h3>

<p>Se entrena un modelo con los predictores seleccionados con la heurística backward elimination y el algoritmo naive bayes.</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image4.png" alt="" /><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image4.png" alt="" /></p>

<p>Atributos descartados: 3, 14, 20, 36, 47, 48, 52, 59</p>

<h3 id="ejercicio-4">Ejercicio 4</h3>

<p>Se entrena un modelo con los predictores seleccionados con una estrategia evolutiva y el algoritmo naive bayes.</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image5.png" alt="" /><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image5.png" alt="" /></p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image6.png" alt="" /></p>

<h3 id="análisis-personal-de-los-resultados">Análisis personal de los resultados</h3>

<p>La mejor exactitud fue obtenida por el modelo en el que se utilizó el enfoque genético para la selección de atributos. Igualmente, considero que se eligieron demasiados atributos, muchos de los cuales no hacen más que incluir ruido en el modelo.</p>

<p>Debido a esto, decido indagar más en los parámetros del bloque optimize selection y encuentro una opción con la que se puede limitar la cantidad de atributos seleccionados. Escojo el valor 10. Los resultados son los siguientes.</p>

<p>10 atributos:</p>

<p><img src="assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image7.png" alt="Interfaz de usuario gráfica Descripción generada automáticamente con confianza media" /> <img src="assets/img/2021-10-10-Diferentes-estrategias-para-Feature-Selection---Dataset-Sonar/media/image8.png" alt="Tabla Descripción generada automáticamente" /></p>

<p>Se obtuvieron mejores resultados y los atributos seleccionados tienen más sentido cuando se los compara con los intervalos en los que las 2 gráficas (mine y rock) están más separadas.</p>

  </div><a class="u-url" href="/Portafolio-ML/2021/10/10/Diferentes-estrategias-para-Feature-Selection-Dataset-Sonar.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Portafolio-ML/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Portafolio-ML/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Portafolio-ML/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/https%3A%2F%2Fgithub.com%2FJoseVilaseca" title="https://github.com/JoseVilaseca"><svg class="svg-icon grey"><use xlink:href="/Portafolio-ML/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
