<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Caso De Estudio 3 Enfermedad Cardíaca | Portafolio José Vilaseca</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Caso De Estudio 3 Enfermedad Cardíaca" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Caso de estudio 3" />
<meta property="og:description" content="Caso de estudio 3" />
<link rel="canonical" href="https://josevilaseca.github.io/Portafolio-ML/2021/12/01/Caso-de-Estudio-3-Enfermedad-Card%C3%ADaca.html" />
<meta property="og:url" content="https://josevilaseca.github.io/Portafolio-ML/2021/12/01/Caso-de-Estudio-3-Enfermedad-Card%C3%ADaca.html" />
<meta property="og:site_name" content="Portafolio José Vilaseca" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-01T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://josevilaseca.github.io/Portafolio-ML/2021/12/01/Caso-de-Estudio-3-Enfermedad-Card%C3%ADaca.html","@type":"BlogPosting","headline":"Caso De Estudio 3 Enfermedad Cardíaca","dateModified":"2021-12-01T00:00:00-06:00","datePublished":"2021-12-01T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://josevilaseca.github.io/Portafolio-ML/2021/12/01/Caso-de-Estudio-3-Enfermedad-Card%C3%ADaca.html"},"description":"Caso de estudio 3","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Portafolio-ML/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://josevilaseca.github.io/Portafolio-ML/feed.xml" title="Portafolio José Vilaseca" /><link rel="shortcut icon" type="image/x-icon" href="/Portafolio-ML/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Portafolio-ML/">Portafolio José Vilaseca</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Portafolio-ML/about/">About Me</a><a class="page-link" href="/Portafolio-ML/search/">Search</a><a class="page-link" href="/Portafolio-ML/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Caso De Estudio 3   Enfermedad Cardíaca</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-12-01T00:00:00-06:00" itemprop="datePublished">
        Dec 1, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      14 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="caso-de-estudio-3">Caso de estudio 3</h1>

<h2 id="predicción-de-enfermedad-de-corazón">Predicción de enfermedad de corazón</h2>

<p>En la actualidad, las enfermedades cardíacas son la principal casusa de muerte a nivel mundial<sup>[1]</sup> . La enfermedad isquémica del corazón fue responsable del 16% de las muertes globales en el 2019. En los Estados Unidos, la principal causa de muerte es otra enfermedad cardíaca llamada enfermedad de la arteria coronaria<sup>[2]</sup>.</p>

<p>Además de esto, entre 3 a 5% de las admisiones a hospitales se deben a pacientes con insuficiencia cardíaca. Un 2% de los costos médicos de los países desarrollados son resultado de dicha condición.<sup>[3]</sup></p>

<p>Debido a este problema mundial, una de las disciplinas en las que se aborda el tema con la intención de mitigar los riesgos y costos, mejorando así la calidad de vida de las personas es Machine Learning. Utilizando diferentes técnicas de aprendizaje automático, se puede estimar con cierto grado de confianza la presencia, el subtipo, y la severidad de una enfermedad cardíaca. Más aún, se pueden predecir eventos como desestabilizaciones, re-hospitalizaciones y mortalidad.</p>

<p><strong>Descripción de los conjutos de datos utilizados</strong></p>

<p>Los conjuntos de datos utilizados en este caso de estudio son 4 datasets distintos. Cada uno de estos contiene medidas de 76 atributos (los mismos atributos en cada dataset), pero los datasets provienen de diferentes instituciones médicas. Estas son: Cleveland Clinic Foundation, Hungarian Institute of Cardiology, Budapest, V.A. Medical Center, Long Beach, CA y University Hospital, Zurich, Switzerland.</p>

<p>Los datasets contienen entre 123 y 294 ejemplos cada uno.</p>

<p>Algunos de los atributos a destacar, utilizados en estudios previos son</p>

<p>1)  Age: edad en años del paciente. Posee una distribución gaussiana con media 53, y desvío 9.</p>

<p>2)  Sex: 1-Masculino 0-Femenino. Predominan los ejemplos masculinos por un gran margen (711 contra 188)</p>

<p>3)  Cp: Tipo de dolor en el pecho. Valores de 1 a 4. El valor 4 es el predominante (asintomatico, 485 ejemplos), mientras que el 1 es el más escaso con solo 45 ejemplos. Los valores 2 y 3 poseen entre 150 y 200 ejemplos.</p>

<p>4)  Trestbps: Presión sanguínea en reposo (medida en mm Hg al ingresar al hospital). Posee una distribución gaussiana. Tiene valores faltantes.</p>

<p>5)  Chol: colesterol en suero (en mg/dl). Distribución no se asemeja a una conocida.</p>

<p>6)  Fbs: nivel de azucar en ayuno &gt; 120 mg/dl (1 = verdadero; 0 = falso). 0 es mucho más prevalente en el dataset (674 vs 135)</p>

<p>7)  Restecg: electrocardiograma en reposo (0-Normal, 1-having ST-T wave abnormality, 2-showing probable or definite left ventricular hypertrophy by Estes’ criteria). 0 es el valor más prevalente, 1 y 2 tienen cardinalidades parecidas (177 y 182)</p>

<p>8)  Thalach: ritmo cardíaco máximo alcanzado. Se asemeja a una distribución normal con un leve sesgo hacia la izquierda.</p>

<p>9)  Exang: angina inducida por ejercicio (1-Si, 0-No). Existen 514 ejemplos para el valor 0 y 330 para el valor 1.</p>

<p>10) Oldpeak: ST depression induced by exercise relative to rest. Distribución no se asemeja a una conocida.</p>

<p>11) Slope: the slope of the peak exercise ST segment (1-upsloping, 2-flat, 3-downsloping). El caso más común es 2, seguido por 1 y el menos prevalente es el 3.</p>

<p>12) Ca: number of major vessels (0-3) colored by flourosopy. Distribución sesgada hacia la derecha. A medida que se aumenta el número de vasos, los ejemplos disminuyen.</p>

<p>13) Thal: 3 = normal; 6 = fixed defect; 7 = reversable defect. Posee 477 valores faltantes. Mayor prevalencia en 3 y 7 (alrededor de 180 ejemplos).</p>

<p>14) Num: diagnosis of heart disease (angiographic disease status) (0- &lt; 50% diameter narrowing, 1- &gt; 50% diameter narrowing). Los posibles valores enteros van del 0 al 4. #0=404, #1=191, #2=130, #3=132, #4=42. 0 significa que el paciente no posee la condición y los valores de 1 a 4 indican la severidad de la misma</p>

<p>Los datos poseen atributos faltantes y están representados con el valor -9.</p>

<p>El dataset de Cleveland posee unas pocas filas corruptas por encoding al final del archivo. Las primeras 282 filas de las 293 no tienen problemas, por lo que esas serán las utilizadas en los siguientes pasos del caso de estudio.</p>

<p><strong>Preparación previa de los datos</strong></p>

<p>Antes de cargar los datasets en rapidminer, es necesario aplicarles una limpieza o transformación para tenerlos estructurados. El script utilizado se puede observar el el repositorio de github del portafolio.</p>

<p><strong>Flujo Rapidminer</strong></p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image1.png" alt="" /></p>

<p><strong>Selección de atributos previa</strong></p>

<p>Debido a la gran cantidad de valores faltantes en algunos atributos, decido descartar los que tengan más de 33% de valores faltantes. También descarto name e id.</p>

<p>Columnas descartadas:</p>

<p>Name, Id, ccf, pncaden, cigs, years, dm, famhist, smoke, thaltime, slope, rldv5, ca, restckm, exerckm, restef, restwm, exeref, exerwm, thal, thalsev, thalpul, earlobe, ramus, om2, cathef, junk.</p>

<p><strong>Estrategias de imputación</strong></p>

<p>Para los predictores con una mayor cantidad de valores nulos dentro de los que no fueron descartados y de tipo categóricos, decido elegir un valor definido que represente que ahí existe un valor nulo. Imputo con el valor -1. Luego, decido imputar los restantes predictores categóricos con su moda (estos tienen menos de 19 valores nulos que equivale aproximadamente a un 2% de los ejemplos). Además, estos poseen una cardinalidad extremadamente alta en su moda, por lo que esta imputación, con un grado de seguridad muy alto, representa el valor exacto que tendrían estos ejemplos. Por último, se decide imputar los últimos valores faltantes con la media, ya que la gran mayoría de estos poseen distribuciones gaussianas o uniformes y valores enteros o reales. Hay 3 predictores en los que hubiera escogido una estrategia de imputación utilizando la mediana por su distribución fuertemente sesgada hacia la derecha (predictores ridv5e, proto y met, véase la imagen a continuación). Se podría aplicar una transformación logarítmica a estos 3 predictores para obtener una distribución más parecida a una gaussiana.</p>

<p>(Distribuciones simil-gaussianas)</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image2.png" alt="" /></p>

<p>(Distribuciones fuertemente sesgadas hacia la derecha)</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image3.png" alt="" /></p>

<p>Para el modelado con KNN, se aplicará además una normalización a los datos, ya que este modelo requiere dicha normalización.</p>

<p>Una nota importante sobre la preparación previa de los datos es que la única estrategia que se realizará previo a los bloques anidados de cross validation es la estrategia de imputación con el valor conocido -1 que representa que el valor es uno no conocido. Esto no depende del set de datos elegido por un Split específico de entrenamiento/test, ya que este valor siempre será el mismo.</p>

<p>La historia es diferente cuando hablamos de la media, moda y la transformación específica que se aplica para normalizar. Estas transformaciones sí dependen de los datos que se eligen, por lo que normalizar o imputar con uno de estos valores antes de separar los conjuntos en entrenamiento y testeo contribuye con un fenómeno llamado contaminación accidental. Dicho fenómeno causa que las estimaciones de las métricas que realizamos para validar nuestros modelos no sean realistas, siendo más optimistas que el rendimiento verdadero que tendrá nuestro modelo.</p>

<p>Por los argumentos expuestos en el párrafo anterior, estas transformaciones se realizarán para los conjuntos de entrenamiento (por ejemplo, se toma la media y desviación estándar del conjunto de entrenamiento), y luego se transforma a los datos de testeo con los valores hallados para la transformación de los datos de entrenamiento.</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image4.png" alt="" />En la imagen a continuación, se pueden observar los operadores dentro del proceso de CV externo. Se puede apreciar que la media y moda (no hay un bloque de normalización debido al algoritmo random forest) se calculan para el conjunto de entrenamiento, y previo a realizar nuestras predicciones con el modelo en el conjunto de testeo, se aplican las imputaciones deseadas en el bloque Apply Model (3).</p>

<p><strong>4- Algoritmos y modelos</strong></p>

<p>En cuanto al algoritmo de aprendizaje para generar el modelo de predicción de enfermedades del corazón, claramente debemos considerar los algoritmos supervisados de clasificación.</p>

<p>Utilizando los estudios Citados por el paper “Heart Failure: Diagnosis, Severity Estimation and Prediction of Adverse Events Through Machine Learning Techniques”<sup>[3]</sup> , diversos grupos de investigadores utilizaron diferentes algoritmos de ML, por lo que elegir uno a priori sin probar una gran variedad de ellos sería un enfoque bastante ingenuo y sesgado en mi opinión. Debido a esto, utilizaré una variedad de algoritmos y elegiré el que mejor se adecúe al dataset elegido.</p>

<p>Como primer paso, propongo utilizar Naive bayes como benchmark inicial de performance. Este utilizará la corrección de Laplace para prevenir el error provocado por el caso en el que exista un valor en el set de test que no haya estado en el set de entrenamiento. Me parece pertinente remarcar que se utilizará sampling estratificado en el bloque de cross validation (siempre utilizaré este tipo de sampling, pero este es especialmente importante para Naive Bayes). Luego, consideraré una serie de algoritmos utilizados por los investigadores de los papers consultados.</p>

<p>Dentro de estos, se podría justificar no utilizar knn por un consumo alto de memoria debido a un dataset de entrenamiento grande, pero con los bajos costos de memoria de hoy en día, este no debería ser un impedimento para un conjunto de datos que pese un par de megas. El orden cuadrático para realizar predicciones (n*(n-1)/2) igualmente podría suponer un problema. Como nuestro dataset no es uno muy grande (no supera los 1000 ejemplos), no habría que descartar este algoritmo. Si utilizaramos otra herramienta como Python-scikitlearn, se debería aplicar one-hot encoding para los predictores categóricos, pero en rapidminer esto no es necesario, ya que se puede utilizar una mixed measure llamada mixed euclidean distance. Para los valores nominales, la distancia es 0 si ambos valores son iguales y 1 si son diferentes. Para valores numéricos, se utiliza la distancia euclídea. Por esto, para que todos los predictores tengan el mismo rango, se normaliza con la transformación min-max (de 0 a 1)</p>

<p>Luego de obtener las métricas para el modelo de KNN, utilizaré difentes tipos de ensambles inicialmente Random Forest y alguna variante de Boosted Trees como AdaBoost o GradientBoostedTrees (Rapidminer) debido a su alta performance para casos de la industria estudiada. Además, como otra justificación para utilizar estos métodos, no existe un requerimiento de que las predicciones tengan que ser extremadamente rápidas, por lo que la utilización de un modelo de Random Forest con miles de árboles no sería un problema. Como los boosted trees son muy susceptibles a outliers, se deberá analizar cuidadosamente la presencia de estos.</p>

<p>SVM es un algoritmo que no podrá ser utilizado para este caso en específico pues se poseen atributos categóricos, no soportados por este algoritmo.</p>

<p>Como este es mi último caso de estudio, decido utilizar toda la batería de conceptos aprendidos en el curso para generar modelos robustos con una validación correcta con la menor contaminación accidental posible. También, se tomarán en cuenta las distintas métricas que podemos obtener de cada modelo para hacer las comparaciones de los modelos obtenidos.</p>

<p>Todos los bloques de cross validation utilizados en la solución, usan la misma semilla y k=5 debido al altísimo costo computacional necesario para tanto entrenar los mejores modelos posibles (utilización de estrategias evolutivas para selección de atributos y para tuning de hiperparámetros) como aplicar una correcta validación de los mismos. Esta correcta validación implica bloques de cross validation anidados.</p>

<p>Naive Bayes</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image5.png" alt="" /></p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image6.png" alt="" /></p>

<p>KNN</p>

<p>Se optimiza k (valores entre 1 y 100)</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image7.png" alt="" /></p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image8.png" alt="" /></p>

<p>Random Forest</p>

<p>Se optimizan los hiperparámetros:</p>

<p>1)  subset_ratio entre 0.2 y 1. (Según [4] Se recomienda utilizar la raíz de la cantidad de predictores para problemas de clasificación)</p>

<p>2)  number_of_trees entre 500 y 3000.</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image9.png" alt="" /></p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image10.png" alt="" />GradientBoostedTrees</p>

<p>Se optimizan los hiperparámetros:</p>

<p>1)  Number_of_trees: de 50 a 500</p>

<p>2)  Learning_rate: de 0.05 a 1</p>

<p>3)  Maximal_depth: de 1 a 10</p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image11.png" alt="" /></p>

<p><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image12.png" alt="" /><img src="https://JoseVilaseca.github.io/Portafolio-ML/assets/img/2021-12-01-Caso-de-Estudio-3---Enfermedad-Cardíaca/media/image13.png" alt="" /></p>

<p><strong>Conclusiones sobre los diferentes modelos</strong></p>

<p>Como se puede ver en las matrices de confusión expuestas anteriormente, dos de los modelos quedan claramente descartados. Estos son KNN y Naive bayes. Su performance no está al nivel de los dos últimos modelos generados, y como lo que buscamos para este caso es maximizar la performance al máximo, no seguimos explorando la posibilidad de utilizar estos algoritmos.</p>

<p>En cambio, la performance de los ensembles escogidos es buena, significativamente mejor que la de los modelos anteriores. Pero eso nos lleva a la pregunta: ¿cuál de los 2 modelos escogemos como el mejor para este caso de estudio?</p>

<p>Normalmente, la métrica a la que se le da más importancia es al accuracy o exactitud. Si nos guiáramos por esa métrica, claramente escogeríamos el modelo entrenado utilizando Random Forest por su aumento de 2.56% en el accuracy promedio frente al otro modelo según la validación cruzada que se realizó.</p>

<p>No obstante, en este caso de estudio, no nos guiaremos por esa métrica absoluta, pues ese no es el punto más importante. Como en este caso un falso negativo (con negativo me refiero a no enfermedad) para la clase 0 (predecir que un paciente no posee la enfermedad cuando en realidad la tiene) es extremadamente costoso en cuanto a costos monetarios y la vida de las personas, considero que lo más importante es obtener la mejor precisión posible. Es de suma importancia priorizar esta métrica para la clase 0.</p>

<p>Las 4 personas que el modelo de Random Forest predijo como clase 0 cuando en realidad eran clase 4 (máximo grado de severidad posible de enfermedad cardíaca) es un error muy grave. Sin embargo, el modelo de GradientBoostedTrees solo se equivocó con casos de la clase 1 (menor grado de severidad) y en menor medida que el otro modelo (por lo tanto tiene mayor precision). También, el modelo de boosted tres posee un mayor recall para la clase 0, lo cual es un extra.</p>

<p>Resumiendo, por la mejor precisión para la clase 0 y por el accuracy comparable al modelo con mejor accuracy que posee el modelo de GradientBoostedTrees, este es el mejor modelo para este caso de estudio.</p>

<p><strong>5- Conclusiones generales sobre el caso abordado y la viabilidad u oportunidad de aplicación de técnicas de machine learning en el mismo.</strong></p>

<p>Comparando los resultados obtenidos por el modelo elegido, este posee una mayor exactitud (no tenemos la precisión) que la que obtuvieron múltiples estudios rigurosos en 1989 citados en las referencias de este caso de estudio<sup>[5]</sup>. Se utilizó una mayor cantidad de atributos (sin abarcar la totalidad de los atributos elegidos por dichos estudios) y un algoritmo más moderno que los que había en la época de los estudios. Es debido a estas razones que se consiguieron mejores resultados.</p>

<p>En cuanto a la viabilidad de la aplicación de técnicas de machine learning para predicción de enfermedad cardíaca, si las personas están dispuestas a generar los datos (sus datos personales) necesarios para que se pueda predecir si se tiene la enfermedad o no, está muy claro que se brindaría un gran beneficio a ellas y a la sociedad entera.</p>

<p><strong>Bibliografía</strong></p>

<p>[1] <a href="https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death">https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death</a></p>

<p>[2] Application of Machine Learning Algorithms to Predict Coronary Artery Calcification With a Sibship-Based Design Yan V. Sun1,* , Lawrence F. Bielak1, Patricia A. Peyser1, Stephen T. Turner2, Patrick F. Sheedy II3, Eric Boerwinkle4, and Sharon L.R. Kardia (2008)</p>

<p>[3] Heart Failure: Diagnosis, Severity Estimation and Prediction of Adverse Events Through Machine Learning Techniques Evanthia E. Tripoliti, Theofilos G. Papadopoulos , Georgia S. Karanasiou, Katerina K. Naka, Dimitrios I. Fotiadis (2016)</p>

<p>[4] https://machinelearningmastery.com/bagging-and-random-forest-ensemble-algorithms-for-machine-learning/</p>

<p>[5] Past Usage:</p>

<p>1. Detrano,~R., Janosi,~A., Steinbrunn,~W., Pfisterer,~M., Schmid,~J.,</p>

<p>Sandhu,~S., Guppy,~K., Lee,~S., \&amp; Froelicher,~V. (1989). {\it</p>

<p>International application of a new probability algorithm for the</p>

<p>diagnosis of coronary artery disease.} {\it American Journal of</p>

<p>Cardiology}, {\it 64},304–310.</p>

<p>-- International Probability Analysis</p>

<p>-- Address: Robert Detrano, M.D.</p>

<p>Cardiology 111-C</p>

<p>V.A. Medical Center</p>

<p>5901 E. 7th Street</p>

<p>Long Beach, CA 90028</p>

<p>-- Results in percent accuracy: (for 0.5 probability threshold)</p>

<p>Data Name: CDF CADENZA</p>

<p>-- Hungarian 77 74</p>

<p>Long beach 79 77</p>

<p>Swiss 81 81</p>

<p>-- Approximately a 77% correct classification accuracy with a</p>

<p>logistic-regression-derived discriminant function</p>

<p>2. David W. Aha &amp; Dennis Kibler</p>

<p>-- Instance-based prediction of heart-disease presence with the</p>

<p>Cleveland database</p>

<p>-- NTgrowth: 77.0% accuracy</p>

<p>-- C4: 74.8% accuracy</p>

<p>3. John Gennari</p>

<p>-- Gennari, J.~H., Langley, P, \&amp; Fisher, D. (1989). Models of</p>

<p>incremental concept formation. {\it Artificial Intelligence, 40},</p>

<p>11–61.</p>

<p>-- Results:</p>

<p>-- The CLASSIT conceptual clustering system achieved a 78.9% accuracy</p>

<p>on the Cleveland database.</p>

  </div><a class="u-url" href="/Portafolio-ML/2021/12/01/Caso-de-Estudio-3-Enfermedad-Card%C3%ADaca.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Portafolio-ML/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Portafolio-ML/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Portafolio-ML/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/https%3A%2F%2Fgithub.com%2FJoseVilaseca" title="https://github.com/JoseVilaseca"><svg class="svg-icon grey"><use xlink:href="/Portafolio-ML/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
